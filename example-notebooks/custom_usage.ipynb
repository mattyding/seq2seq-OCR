{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Usage\n",
    "This notebook demonstrates how to customize the notebook for your needs.\n",
    "\n",
    "## English Lexicon/Hashsets\n",
    "First up, the model 'recognizes' English words via two saved English lexicon files. The English lexicon compiled from millions of documents from the COHA corpus. The common lexicon is compiled from Google's 10000 most-used words list.  \n",
    "\n",
    "The English lexicon is not comprehensive -- there are still many valid words that aren't contained within it, but it provides pretty broad coverage for this historical context."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# these two lines help with locating the file from this notebook\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from seq2seqocr import Seq2SeqOCR\n",
    "\n",
    "model = Seq2SeqOCR()  # init model\n",
    "\n",
    "print(\"Size of English Lexicon: \", len(model.english_lexicon))\n",
    "print(\"Size of Common Lexicon: \", len(model.common_lexicon))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-06 12:16:48.197448: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of English Lexicon:  47886\n",
      "Size of Common Lexicon:  8591\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to change the contents of these lexicons, you can edit the path in settings.py to a different file or you can manually add them. The two lexicons are implemented as hashsets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "SPONGEBOB_REFERENCE = 'goofygooberrock'\n",
    "\n",
    "print(\"Test word in English lexicon before adding: \", SPONGEBOB_REFERENCE in model.english_lexicon)\n",
    "\n",
    "model.english_lexicon.add(SPONGEBOB_REFERENCE)  # adds word to set\n",
    "\n",
    "print(\"Test word in English lexicon after adding: \", SPONGEBOB_REFERENCE in model.english_lexicon)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test word in English lexicon before adding:  False\n",
      "Test word in English lexicon after adding:  True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that these added words do not persist through different instances of the seq2seq model class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "other_instance = Seq2SeqOCR()\n",
    "\n",
    "print(\"Test word in seperate instance's lexicon: \", SPONGEBOB_REFERENCE in other_instance.english_lexicon)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Test word in seperate instance's lexicon:  False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also remove words from the lexicon in the same way. Any functionality that exists with Python hashsets persists into these two lexicons."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(\"Differences between both set instances: \", model.english_lexicon.difference(other_instance.english_lexicon))\n",
    "\n",
    "model.english_lexicon.remove(SPONGEBOB_REFERENCE)\n",
    "\n",
    "print(\"Test word in English lexicon after removal: \", SPONGEBOB_REFERENCE in model.english_lexicon)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Differences between both set instances:  {'goofygooberrock'}\n",
      "Test word in English lexicon after removal:  False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If there are many changes you would like to make or if you would like those changes to persist each through each instance, I would recommend you pickle a new English lexicon and change the ENGLISH_LEXICON_PKL and COMMON_LEXICON_PKL variables in the settings.py file.\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Compound-Splitting\n",
    "One of the pre-processing checks involves recursively checking if substrings in a word are valid english words. There are a few checks on this splitting. Firstly, there is a 2-character 'buffer' around the end of the words, to prevent common prefixes and endings from throwing out false positives. Second, the average of all split-words must be at least 4 characters for the same reason.  \n",
    "\n",
    "However, beacuse short words like 'er' and 'an' often lead to false positives, we have removed them from the common lexicon used to identify splittings. This can lead to issues, as joined-together words such as 'at the'->'atthe' will not be recognized and split. In the seq2seqocr.py file, we have defined a function, populate_compound_memory() that populates the memoized set with several of these common short-word compounds. Before the model tries to split these words, it always checks the memoized dictionary to see if a splitting has already been performed, and returns the entry if it finds one.  \n",
    "\n",
    "This long section is just to say that you can define your own mappings that you want the program to correct in pre-processing. To do so, you can add entries in populate_compound_memory() using the provided format, or you can manually add them to the dict as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "HARRY_POTTER_REFERENCE = 'youreawizardharry'\n",
    "\n",
    "print(\"Model preprocessing before adding test phrase: \", model.preprocess(HARRY_POTTER_REFERENCE))\n",
    "\n",
    "model.memoized_words[HARRY_POTTER_REFERENCE] = \"im a what?\"\n",
    "\n",
    "print(\"Model preprocessing after adding test phrase: \", model.preprocess(HARRY_POTTER_REFERENCE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model preprocessing before adding test phrase:  youreawizardharry\n",
      "Model preprocessing after adding test phrase:  im a what?\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that this does not work if the 'key' in the translation is a valid English word because that case is handled before the memoized dictionary is checked. For instance,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "MARCO_POLO_REFERENCE = 'marco'\n",
    "\n",
    "print(\"Test phrase recognized as valid English word? \", MARCO_POLO_REFERENCE in model.english_lexicon)\n",
    "\n",
    "print(\"Model preprocessing before adding test phrase: \", model.preprocess(MARCO_POLO_REFERENCE))\n",
    "\n",
    "model.memoized_words[MARCO_POLO_REFERENCE] = 'polo'\n",
    "\n",
    "print(\"Model preprocessing after adding test phrase: \", model.preprocess(MARCO_POLO_REFERENCE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test phrase recognized as valid English word?  True\n",
      "Model preprocessing before adding test phrase:  marco\n",
      "Model preprocessing after adding test phrase:  marco\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also remember that all text gets converted to lowercase and punctuation gets stripped during pre-processing. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "PUNCTUAL_REFERENCE = 'LOL!!!'\n",
    "\n",
    "print(\"Model preprocessing before adding test phrase: \", model.preprocess(PUNCTUAL_REFERENCE))\n",
    "\n",
    "model.memoized_words[PUNCTUAL_REFERENCE] = 'laughing out loud exclamation mark x3'\n",
    "\n",
    "print(\"Model preprocessing after adding test phrase: \", model.preprocess(PUNCTUAL_REFERENCE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model preprocessing before adding test phrase:  lol\n",
      "Model preprocessing after adding test phrase:  lol\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "0df766557e9e52c50ed33f63d0ce7ef29166bb38e4b1cc05d489187aa19089d7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}